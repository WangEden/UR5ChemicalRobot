#include "Function.h"
#include <QDebug>
#include <QThread>
#include <QTimer>
#include <opencv2/xfeatures2d.hpp>


Function::Function(QObject *parent) : QObject(parent)
{
}

Function::~Function()
{
}

void Function::recv_mat(cv::Mat mat)
{
    current_mat = mat;
}

void Function::init_UR5_position(UR5 * ur5)
{
    // vector<double> init_pose = {-0.0876918, -0.482308, 0.329788, 0.0350037, 3.13, -0.0103306};
    vector<double> init_pose = {-0.0619614, -0.443324, 0.231807, -0.0199154, -3.1295, 0.00661932};
    // vector<double> init_pose = {-0.0876918, -0.482308, 0.329788, -0.0350037, -3.13, 0.0103306};
    ur5->moveJP(init_pose);
}

void Function::shelf_grasp(Camera * camera, UR5 * ur5, cv::Mat matrix) {
    qDebug() << "子线程" << QThread::currentThreadId();
    
    // object points
    vector<vector<Point3d>> object_points = {
    {Point3d(0.00, 0.00, 0.00), Point3d(0.00, 0.01, 0.00), Point3d(0.00, 0.02, 0.00), Point3d(0.05, 0.00, 0.00), Point3d(0.05, 0.02, 0.00)}, \
    {Point3d(0.00, 0.01, 0.00), Point3d(0.01, 0.00, 0.00), Point3d(0.01, 0.01, 0.00), Point3d(0.01, 0.02, 0.00), Point3d(0.02, 0.00, 0.00)}, \
    {Point3d(0.00, 0.01, 0.00), Point3d(0.00, 0.02, 0.00), Point3d(0.01, 0.00, 0.00), Point3d(0.02, 0.01, 0.00), Point3d(0.02, 0.02, 0.00)}};
    
    // image points
    vector<Point2d> center_points_all, center_points_5;
    vector<Vec3f> circles;
    Point2d center;
    Vec3f circle;
    vector<Point2f> projection_points;

    // image processing
    Mat color_mat, hsv_mat, mask_low, mask_high, mask, gray_mat, shelf_mask;
    Mat labels, stats, centroids;
    Mat intrinsics_mat, distCoeffs;
    tuple<Mat, Mat> images;
    tuple<Mat, Mat, vector<Point2f>, string> shelf_pose;

    // calculate pose
    Mat V_Shelf2Cam, R_Shelf2Cam, T_Shelf2Cam, RT_Shelf2Cam, RT_Shelf2Base, RT_End2Base;
    Mat R_Cam2End, T_Cam2End, RT_Cam2End;
    string color_filename, type;

    // vector<double> init_pose = {-0.0526588, -0.589644, 0.329795, 0.0195414, 3.13016, -0.0104116};
    // vector<double> target_pose, target_pose2;

    // vector<double> measure_pose_Rough = {-0.0526588, -0.589644, 0.329795, 0.0195414, 3.13016, -0.0104116};
    /*
    -0.0807703
    -0.381305
    0.255057
    -0.0502337
    -3.13539
    0.00225565
    */
    vector<double> measure_pose_Rough = {-0.0619614, -0.443324, 0.231807, -0.0199154, -3.1295, 0.00661932};
    vector<double> measure_pose_Precise, target_pose_1, target_pose_2;
    
    // Mat P_Shelf_1 = (Mat_<double>(4, 1) << 0.025, 0.01, -0.090, 1.0);
    // Mat P_Shelf_1_1 = (Mat_<double>(4, 1) << 0.025, 0.05, -0.150, 1.0);
    // Mat P_Shelf_2 = (Mat_<double>(4, 1) << 0.025, 0.01, -0.030, 1.0);
    // Mat target_P_1, target_P_1_1, target_P_2;

    Mat P_Shelf_PreciseMeasure_P = (Mat_<double>(4, 1) << 0.025, 0.03, -0.120, 1.0);
    Mat P_Shelf_PreciseMeasure_N = (Mat_<double>(4, 1) << 0.025, -0.03, -0.120, 1.0);
    Mat P_Shelf_Destination_1  = (Mat_<double>(4, 1) << 0.025, 0.01, -0.070, 1.0);
    Mat P_Shelf_Destination_2  = (Mat_<double>(4, 1) << 0.025, 0.01, -0.030, 1.0);
    Mat target_P_PreciseMeasure, target_P_Destination_1, target_P_Destination_2;

    // vector<double> orignal_rotation = {-0.0204577, -3.13029, 0.0247043};
    vector<double> orignal_rotation = {-0.0199154, -3.1295, 0.00661932};
    vector<double> preciseMeasure_rotation;

    int radius;
    double projection_error;
    bool save = true, projection = true;

    // const double x_max = 0.13275;
    // const double x_min = -0.20079;
    // const double y_max = -0.38654;
    // const double y_min = -0.68844;
    // const double z_max = 0.45000;
    // const double z_min = 0.09247;

    try {
    // 读取相机到末端的位姿
    cv::FileStorage fs_read("../configs/config.yml", FileStorage::READ);
    if (fs_read.isOpened()) {
        fs_read["R_Cam2End"] >> R_Cam2End;
        fs_read["T_Cam2End"] >> T_Cam2End;
        fs_read.release();
    }
    RT_Cam2End = ur5->R_and_T2RT(R_Cam2End, T_Cam2End);
    std::cout << "RT_Cam2End" << RT_Cam2End << std::endl;

    // 移动到初始位置
    ur5->moveJP(measure_pose_Rough);

    int times= 0;

    for (int i = 0; i < 2; i++)
    {
        while (1) 
        {
            std::cout << "第" << times << "次识别------------------------------" << std::endl;
            // 获取图片
            images = camera->get_images();
            color_mat = get<0>(images);

            // 获取圆
            circles = camera->get_circles(save, i);

            // 滤波
            cv::medianBlur(color_mat, color_mat, 3);
            cv::imwrite("../debug/images/"+to_string(times)+"-img1-original.png", color_mat);
            std::cout << "存入原始图片" << std::endl;

            // 颜色识别提取
            cv::cvtColor(color_mat, hsv_mat, cv::COLOR_BGR2HSV);
            cv::inRange(hsv_mat, cv::Scalar(0, 0, 0), cv::Scalar(10, 255, 255), mask_low);
            cv::inRange(hsv_mat, cv::Scalar(160, 0, 0), cv::Scalar(179, 255, 255), mask_high);
            cv::addWeighted(mask_low, 1, mask_high, 1, 0, mask);
            cv::imwrite("../debug/images/"+to_string(times)+"-img2-mask.png", mask);
            std::cout << "存入mask图片" << std::endl;

            // 形态学处理
            cv::Mat element1 = cv::getStructuringElement(cv::MORPH_ELLIPSE, cv::Size(5, 5));
            cv::Mat element2 = cv::getStructuringElement(cv::MORPH_ELLIPSE, cv::Size(2, 2));
            cv::dilate(mask, mask, element1);
            cv::imwrite("../debug/images/"+to_string(times)+"-img3-morphomask.png", mask);
            std::cout << "存入形态学处理后的mask图片" << std::endl;

            // 画出筛选之前的圆
            cv::Mat color_copy = color_mat.clone();
            for (size_t i = 0; i < circles.size(); i++)
            {
                circle = circles[i];
                center = Point2d(circle[0], circle[1]);
                radius = circle[2];
                cv::circle(color_copy, center, radius, cv::Scalar(255, 0, 255), 3, cv::LINE_AA);
            }
            std::cout << "筛选前圆的数量" << circles.size() << std::endl;
            cv::imwrite("../debug/images/"+to_string(times)+"-img4-circle-before.png", color_copy);
            std::cout << "存入筛选前查找的圆的图片" << std::endl;

            // 筛选圆，选出红色的圆
            for (size_t i = 0; i < circles.size(); i++)
            {
                if (mask.at<uchar>(cvRound(circles[i][1]), cvRound(circles[i][0])) == 255)
                {
                    circle = circles[i];
                    center = cv::Point2d(circle[0], circle[1]);
                    center_points_all.push_back(center);
                    radius = circle[2];
                    cv::circle(color_mat, center, radius, cv::Scalar(255, 0, 255), 3, cv::LINE_AA);
                }
            }
            // 通过颜色筛选完后数量不足5个，重新识别
            if (center_points_all.size() < 5)
            {
                times++;
                sleep(1);
                continue; // 重新识别
            }
            std::cout << "筛选后圆的数量" << center_points_all.size() << std::endl;
            std::cout << "存入筛选后查找的圆的图片" << std::endl;
            imwrite("../debug/images/"+to_string(times)+"-img5-circle-after.png", color_mat);
            std::cout << "本次识别圆的数量" << center_points_all.size() << std::endl;

            // 获取试管架位姿
            std::cout << "开始计算位姿..." << std::endl;
            bool get_pose = false;
            shelf_pose = camera->get_shelf_pose(object_points, center_points_all, get_pose);
            type = get<3>(shelf_pose);
            // 识别失败，重新识别
            if (type == "none")
            {
                std::cout << "识别失败，重新识别" << std::endl;
                center_points_all.clear();
                auto current_pose_tuple = ur5->getCurrentPositions();
                vector<double> current_pose = get<1>(current_pose_tuple);
                if (times % 2 == 0) {
                    current_pose[2] += 0.01; // z轴上升1cm后重新识别
                    ur5->moveJP(current_pose);
                }
                else {
                    current_pose[2] -= 0.01; // z轴下降1cm后重新识别
                    ur5->moveJP(current_pose);
                }
                times++;
                sleep(1);
                continue;
            }
            else {
                break;
            }
        }

        type = get<3>(shelf_pose);
        cout << type << endl;
        R_Shelf2Cam = get<0>(shelf_pose);
        T_Shelf2Cam = get<1>(shelf_pose);
        projection_points = get<2>(shelf_pose);
        RT_Shelf2Cam = ur5->R_and_T2RT(R_Shelf2Cam, T_Shelf2Cam);

        for (size_t i = 0; i < projection_points.size(); i++)
        {
            Point2f pt = projection_points[i];
            cv::circle(color_mat, pt, 4, Scalar(0, 0, 255), -1);
        }
        cout << "存入重投影的图片" << endl;
        imwrite("../debug/images/"+to_string(times)+"-img6-projection.png", color_mat);

        // calculate pose
        tuple<cv::Mat, cv::Mat> array2 = ur5->getCurrentRT();
        RT_End2Base = ur5->R_and_T2RT(get<0>(array2), get<1>(array2));
        RT_Shelf2Base =  RT_End2Base * RT_Cam2End * RT_Shelf2Cam;

        if (i == 0)
        {
            // 移动到精确识别位置
            if (type == "upP")
            {
                target_P_PreciseMeasure = RT_Shelf2Base * P_Shelf_PreciseMeasure_P;
            }
            else if (type == "upN")
            {
                target_P_PreciseMeasure = RT_Shelf2Base * P_Shelf_PreciseMeasure_N;
            }

            // 获取目标旋转矩阵
            Mat_<double> orignal_rotation_mat(1, 3, orignal_rotation.data());
            Mat OrignalR = ur5->eulerAnglesToRotationMatrix(orignal_rotation_mat);
            Mat TargetR = OrignalR * R_Cam2End * R_Shelf2Cam;
            cv::Mat target_rotation_pose;
            cv::Rodrigues(TargetR, target_rotation_pose);
            cout<<"targetPreciseMeasure_rotation_vector: \n" << target_rotation_pose << endl;

            cout << "target_P_PreciseMeasure:" <<endl;
            cout << target_P_PreciseMeasure << endl;
            measure_pose_Precise.push_back(target_P_PreciseMeasure.at<double>(0));
            measure_pose_Precise.push_back(target_P_PreciseMeasure.at<double>(1));
            measure_pose_Precise.push_back(target_P_PreciseMeasure.at<double>(2));
            measure_pose_Precise.push_back(target_rotation_pose.at<double>(0));
            measure_pose_Precise.push_back(target_rotation_pose.at<double>(1));
            measure_pose_Precise.push_back(target_rotation_pose.at<double>(2));

            preciseMeasure_rotation.push_back(target_rotation_pose.at<double>(0));
            preciseMeasure_rotation.push_back(target_rotation_pose.at<double>(1));
            preciseMeasure_rotation.push_back(target_rotation_pose.at<double>(2));
            
            cout << "Position1-------------------------------------" << endl;
            for (auto element : measure_pose_Precise)
            {
                cout << element << "\t" << endl;
            }
            cout << "Position1-------------------------------------" << endl;

            ur5->moveJP(measure_pose_Precise);
            cout << "移动到精确识别位置----------进行再次识别---------" << endl;
            times++;
        }
        else
        {
            target_P_Destination_1 = RT_Shelf2Base * P_Shelf_Destination_1;
            target_P_Destination_2 = RT_Shelf2Base * P_Shelf_Destination_2;

            // 获取目标旋转矩阵
            // Mat_<double> preciseMeasure_rotation_mat(1, 3, preciseMeasure_rotation.data());
            Mat_<double> preciseMeasure_rotation_mat(1, 3, orignal_rotation.data());
            Mat PreciseMeasureR = ur5->eulerAnglesToRotationMatrix(preciseMeasure_rotation_mat);
            Mat TargetR = PreciseMeasureR * R_Shelf2Cam * R_Cam2End;

            cv::Mat target_rotation_pose;
            cv::Rodrigues(TargetR, target_rotation_pose);
            cout<<"targetDestination_rotation_vector: \n" << target_rotation_pose << endl;

            cout << "target_P_Destination_1:" <<endl;
            cout << target_P_Destination_1 << endl;
            target_pose_1.push_back(target_P_Destination_1.at<double>(0));
            target_pose_1.push_back(target_P_Destination_1.at<double>(1));
            target_pose_1.push_back(target_P_Destination_1.at<double>(2));
            target_pose_1.push_back(target_rotation_pose.at<double>(0));
            target_pose_1.push_back(target_rotation_pose.at<double>(1));
            target_pose_1.push_back(target_rotation_pose.at<double>(2));

            cout << "target_P_Destination_2:" <<endl;
            cout << target_P_Destination_2 << endl;
            target_pose_2.push_back(target_P_Destination_2.at<double>(0));
            target_pose_2.push_back(target_P_Destination_2.at<double>(1));
            target_pose_2.push_back(target_P_Destination_2.at<double>(2));
            target_pose_2.push_back(target_rotation_pose.at<double>(0));
            target_pose_2.push_back(target_rotation_pose.at<double>(1));
            target_pose_2.push_back(target_rotation_pose.at<double>(2));

            cout << "Position2-------------------------------------" << endl;
            for (auto element : target_pose_1)
            {
                cout << element << "\t" << endl;
            }
            cout << "Position2-------------------------------------" << endl;

            for (auto element : target_pose_2)
            {
                cout << element << "\t" << endl;
            }

            cout << "移动到目标位置" << endl;
            ur5->moveJP(target_pose_1);
            // ur5->moveJP(target_pose_2);
        }
    }
    emit shelf_grasp_finished();
    }
    catch (const std::exception& e) {
        std::cerr << e.what() << '\n';
        emit shelf_grasp_finished();
    }
}
